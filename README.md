PySpark Smart Schema Automation
Smart Schema Automation 

Lightweight PySpark utility that automatically infers and recommends an optimal Spark schema for CSV or JSON datasets based on a configurable sample size.
It analyzes data types and field patterns, then outputs a recommended schema along with column-level correlation and confidence metrics to help you validate inference accuracy.

Key Features
- Adaptive schema inference for CSV and JSON files
- Configurable sampling for large datasets
- Outputs recommended StructType for direct Spark use
- Provides correlation scores and confidence indicators per column
- Easily integrates into existing ETL or data-validation pipelines


Use Case

Ideal for data engineers and analysts who need a fast, automated way to generate reliable Spark schemas without manually inspecting data samples.

